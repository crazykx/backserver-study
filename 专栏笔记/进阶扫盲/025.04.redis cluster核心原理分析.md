###### 基础通信原理

1. redis cluster 节点采取 gossip 协议进行通信
   + gossip:每个节点的数据是完整的, 更新请求断断续续, 有一定时延  可能: 在做 reshard 时, 去做另外一个操作,会出现: configuration error, 达成一致
   
   + 集中式: 元数据的更新和读取时效性非常好, 一旦元数据出现了变更, 立即就更新到了集中式的存储中   不好: 所有元数据的更新压力全部集中在一个地方, 可能会导致元数据的存储有压力
2. +10000端口号
   
   + 每个节点有一个专门用与节点间 gossip 内部通信的端口, 自己提供服务的端口号+10000, 比如:6379, 那么节点间通信就是 17001
   
   + 每个节点每隔一段时间都会往另外几个节点发送 ping 消息, 同时其他几个节点收到后 返回 pong
3. 交换的信息
   + 故障信息
   
   + 节点的增加和移除
   
   + hash slot 信息

2. gossip 协议
   + meet: 某个节点发送 meet 给新加入的节点, 让新节点加入集群中, 然后给新节点就会开始与其他节点进行通信
   
   + ping: 每个节点都会频繁给其他节点发送 ping, 互相通过 ping 交换 自己的状态,自己维护的集群元数据
   
   + pong: 包含自己的状态和其他信息, 也可以用于信息广播和更新
   
   + fail: 某个节点判断另一个节点 fail 之后, 就发送 fail 给其他节点, 通知其他节点, 指定的节点宕机了
   
2. ping 深入

   + ping 很频繁, 每次都携带元数据, 加重网络负担

   + 每个节点每秒钟执行 10 次 ping, 每次会选择 5 个最久没有通信的其他节点

   + 如果发现某个节点通信延时达到了 cluster_node_timeout / 2 , 那么会立即发送 ping, 避免数据交换延时过长, 落后时间太长

   + cluster_node_timeout 可以调节, 如果调节比较大, 那么会降低发送的频率

   + 每次 ping 是带上自己的节点信息, 还有就是带上 1/10 其他节点的信息, 发送出去,进行数据交换

   + 每次至少包含其他三个节点的信息, 最多包含 总结点数-2 个其他节点的信息





###### 面向集群的 jedis 内部实现原理

开发, Jedis, redis 的 java client 客服端, redis cluster, jedis cluster api                      

redis-cli -c 自动重定向

1. 请求重定向

   1. 客户端可能会挑选任意一个 redis 实例去发送命令, 每个 redis 收到后, 都会计算 hash slot, 如果在本地就在本地处理, 否则返回 moved 给客户端进行重定向

      cluster keyslot mykey : 可以查看一个可以对应的 hash slot 是什么

   2. 计算 hash slot

      + 根据 key 值计算 CRC16 值,然后对 16384 取模, 拿到对应的 hash slot

      + 用 hash tag 可以手动指定key 对应的 slot, 同一个 hash tag 下的 key, 都会在一个hash slot 中, 比如 set mykey1:{100} 和 set mykey2:{100}

   3. hash slot 查找

      + 节点间通过 gossip 协议进行数据交换, 就知道每个hash slot 在哪个节点上

2. smart jedis

   1. 什么是 smart Jedis

      + 基于重定向的客户端, 很消耗网络 IO, 因为大部分情况下, 可能都会出现一次请求重定向, 才能找到正确的节点

      + 所以大部分的客户端, 比如 java redis客户端, 就是 jedis, 都是 smart 的

      + 本地维护一份 hashslot —> node 的映射表, 缓存, 大部分情况下, 直接走本地缓存就可以找到 hashslot —> node, 不需要通过节点进行 moved 重定向

   2. JedisCluster的工作原理

      - 在 JedisCluster 初始化的时候,就会随机选择一个node, 初始化 hashslot —> node 映射表, 同时为每个节点创建一个 JedisPool 连接池

      - 每次基于 JedisCluster 执行操作, 首先 JedisCluster 都会在本地计算 key 的 hashslot 值, 然后在本地映射表找到对应的节点
      - 如果进行了 reshard 这样的操作, 可能 hashslot 已经不在那个node 上了, 就会返回 moved, 如果 JedisCluster API 发现对应的节点返回 moved, 那么利用该节点的元数据, 更新本地hashslot —> node 映射表的缓存, 重复上面几个步骤, 直到找到相对应的节点, 如果重试次数超过 5 次, 那么就报错, JedisClusterMaxRedirectionException





###### redis cluster 高可用与主备切换

1. 判断节点宕机

   + 如果一个节点以为另外一个节点宕机, 那么就是 pfail 主观宕机
   + 如果多个节点都认为另外一个节点宕机了, 那么就是 fail
   + 在 cluster-node-timeout 内, 某个节点一直没有返回 pong, 那么就认为 pfail
   + 如果一个节点认为某个节点 pfail 了, 那么会在 gossip ping消息中, ping 给其他节点, 如果超过半数的节点都认为 pfail 了, 那么就会变成 fail

2. 从节点过滤

   + 对宕机的 master node, 从其所有的 slave node 中, 选择一个切换成 master node
   + 检查每个 slave node 与 master node 断开连接的时间, 如果超过了 cluster-node-timeout * cluster-slave-validity-factor, 那么就没有资格切换成 master
   + 这个也是跟哨兵一样的, 从节点超时过滤的步骤

3. 从节点选举

   + 哨兵: 对所有从节点进行排序, slave priority, offset, run id

   + 每个从节点, 都根据自己对master 复制数据的 offset, 来设置一个选举时间, offset 越大(复制数据越多) 的从节点, 选举时间越靠前, 优先进行选举

   + 所有的 master node 开始给要进行选举的 slave 进行投票, 如果大部分 master node(N/2 + 1)都投票给了某个从节点, 那么选举通过, 那么选举通过, 那个从节点可以切换成 master

   + 从节点执行主备切换, 从节点切换为主节点

4. 与哨兵相比
   + 整个流程与哨兵非常相似, redis cluster 功能强大, 直接集成了 replication 和 sentinal 的功能

