1. rabbitMQ
   - 还没写入消息队列,网络传输过程中丢失
     - 支持事务,回滚, 同步的,阻塞卡住等待你是成功还是失败
     - channel 改成 confirm 模式, rabbitmq接收到消息后,回调本地的一个方法,发送失败也会回调一个失败方法
   - 消息队列暂存在内存中还没写入时直接挂了
     - 开启 rabbitmq 的持久化, 消息写入后持久化到硬盘 罕见: rabbitmq 还没持久化就挂了, 导致少量内数据丢失, 这个概率较小
     - 1.创建 queue 的时候将其设置为持久化的, 保证 rabbitmq 持久化 queue 的元数据, 但是不会持久化 queue 里的数据
     - 2.发送消息时将消息的 deleveryMode 设置为 2, 将消息设置为持久化的
     - 同时设置这两个才行
     - 可以和 生产者的 confirm 机制配合起来, 只有当消息被持久化到磁盘后才会通知生产者 ack 了
   - 消费者拉取了消息但是还没消费直接挂了,此时消息队列以为消费者消费了
     - 消费者的 autoAck 机制
     - 消费到数据之后,消费者会自动 autoAck 了, 若此时消费者系统宕机了,那条消息就会丢失
2. kafka
   - 案例
     - kafka 消费者消费到了数据之后是写到一个内存的 queue 里先缓冲一下, 结果有的时候,刚把消息写入queue,消费者就自动提交了offset,此时重启了系统,导致内存queue里还没来得及处理的数据就丢失了
     - 关闭自动提交 offset, 此时会存在处理完还没提交 offset ===> 保持幂等性就好了
   - kafka 某个 broker 宕机, 然后重新选举 partition 的leader时
     - leader 刚接受消息, 结果 followers 还没来得及同步,结果 leader 挂了, 然后选举其他follower作为leader时,这时数据就丢了
       - 解决方法: 起码设置4个参数
       - 给这个 topic 设置 replication.factor 参数: 这个值必须大于1, 要求每个partition必须至少有两个副本
       - kafka服务端设置 min.insync.replicas 参数: 这个值必须大于 1, 要求 leader 至少感知到有至少一个 follower2 还跟自己保持联系, 没掉队, 这样才能确保 leader 挂了还有一个 follower
       - 在 producer 端设置 acks=all: 要求每条数据必须是写入所有 replica 之后才能认为是写成功了
       - 在 producer 端设置 retries=MAX(): 这个要求是一旦写入失败,就无限重试,卡在这里了
     - 生产环境就是按照上述要求配置的, 这样配置之后, 至少在 kafka broker 端 leader所在broker 发生故障进行leader切换时数据不丢失